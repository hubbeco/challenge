# data-science challenge

<img src="https://raw.githubusercontent.com/hubbeco/challenge/master/data-science/assets/images/under-construction-669123b5e6c3d0c7.png" width="188">

### TODO



### DescriÃ§Ã£o do desafio

> **_NOTE:_** Este Ã© um desafio aberto, nÃ£o hÃ¡ uma soluÃ§Ã£o predefinida, nem objetivos especÃ­ficos.
> EntÃ£o, divirta-se ğŸ˜ƒ

Disponilizamos 2 datasets, cada um deles em 2 formatos. Eles variam em grau de dificuldade e em tipos de habilidades testadas.
Todos os datasets estÃ£o disponÃ­veis em AWS S3 e em google drive.
Todos os datasets sÃ£o de domÃ­nio pÃºblico, porem representam atividades que vocÃª vai encontrar usualmente na Zedia.
Todos os datasets permitem diferentes analises; o seu senso critico de decidir o que analisar faz parte do desafio.
Todos os datasets podems ser analisados sem a necessidade de hardware ou software proprietÃ¡rio ou pago.

Escolha apenas um desses 2, aquele que vocÃª julgar que se enquadra melhor no seu perfil
(seus conhecimentos, seus interesses, e aquilo que vocÃª quer demonstrar para nÃ³s que vocÃª domina).
Analize o dataset com as ferramentas que vocÃª preferir: python, matlab, serviÃ§os cloud, softwares low-code, qualquer ferramenta que vocÃª julgar adequada.
Ao final do desafio, vocÃª deve nos enviar o link para um repositÃ³rio (github, gitlab ou similar) contendo a implementaÃ§Ã£o de sua anÃ¡lise
(qualquer cÃ³digo, script, ou similar utilizado para realizar a anÄºise) e um arquivo pdf chamado "relatorio.pdf".
O relatÃ³rio deve ter entre 1 e 5 pÃ¡ginas, em qualquer formataÃ§Ã£o que vocÃª preferir, contendo qualquer quantidade de imagens/diagramas/tabelas/etc que vocÃª preferir.

Deve conter ao menos as seguintes seÃ§Ãµes:
* SumÃ¡rio: um ou dois paragrafos descrevendo o que foi analisado e quais resultados foram obtidos. Seja breve, nÃ£o inclua imagens nem referencias.
ImplementaÃ§Ã£o: dÃª uma visÃ£o geral de como vocÃª implementou, ferramentas utilizadas, etc.
NÃ£o Ã© preciso ser uma extensa documentaÃ§Ã£o, nos vamos olhar o seu cÃ³digo de qualquer maneira. CÃ³digo limpo e comentado vale mais do que mil pÃ¡ginas de documentaÃ§Ã£o ğŸ˜

Resultados: o que vocÃª descobriu sobre os dados, mÃ©tricas (por exemplo, acurÃ¡cia) caso vocÃª treinou algum modelo, etc.
NÃ£o hÃ¡ necessidade de capa, linguajar super rebustado, ou qualquer outra formalidade.
Mantenha simples e direto.

NÃ£o hÃ¡ necessidade de "atirar para todos os lados" para demonstrar o seu conhecimento, seja focado e claro:
defina aquilo que vocÃª quer fazer/analisar, implemente o que for necessÃ¡rio, apresente os seus resultados. Ponto final.

Idealmente, vocÃª conseguir definir seus objetivos na forma de uma Ãºnica pergunta, segue um processo metodolÃ³gico
para responder/resolver aquilo que vocÃª se propos, e no final obtem resultados que respondem a pergunta.

VocÃª Ã© livre para incluir qualquer trecho de cÃ³digo nÃ£o produzido por vocÃª
(incluindo stack overflow, chatgpt, tutoriais, artigos cientÃ­ficos, repositÃ³rios abertos, etc),
porÃ©m referencie: inclua links do stack overflow no cÃ³digo sempre que pegar um trecho significado de uma soluÃ§Ã£o,
mentione tutoriais sempre que tomar forte inspiraÃ§Ã£o deles, etc.

### Desafio 1

Principais habilidades: processamento de dados tabulares, sÃ©ries temporais, telemetria.
Esse dataset Ã© uma tabela contendo registros de acessos a uma aplicaÃ§Ã£o web. Cada linha
representa um cliente fazendo uma requisiÃ§Ã£o para um backend, indicando que o usuÃ¡rio ainda
estÃ¡ conectado Ã  aplicaÃ§Ã£o ou indicando que o usuÃ¡rio realizou alguma atividade. O dataset
possui as seguintes colunas: timestamp (unix timestamp de quando a requisiÃ§Ã£o foi recebida), ...

O dataset estÃ¡ disponÃ­vel em dois formatos:

1. Delta. O dataset possui X linhas. Link do S3: https://abc. Link do google drive: https://abc.

2. CSV. O dataset foi reduzido para X linhas. Link do S3: https://abc. Link do google drive: http
s://abc.

SugestÃµes do que pode ser analisado:
* Treinar um modelo de classificaÃ§Ã£o para a coluna X
* Agregar os dados realizando o count de acessos vs cidade, e treinar um modelo de regressÃ£o para o count
* Time series forecasting sobre o count ao longo do tempo
* Enriquescer os dados com outras fontes pÃºblicas (por exemplo, IBGE)

### Desafio 2

Principais habilidades: manipulaÃ§Ã£o de media, visÃ£o computacional, processamento de linguagem
natural, processamento de audio.
Este dataset Ã© sobre um episÃ³dio do cartoon "Popeye". O episÃ³dio foi dividido em trechos de 10
segundos. O idioma Ã© inglÃªs.


O dataset estÃ¡ disponÃ­vel em dois formatos:

1. Delta. Cada linha corresponde a um trecho de 10s. As seguintes colunas estÃ£o disponÃ­veis:
video (binÃ¡rio, contendo o conteÃºdo do arquivo mp4 desse trecho de video), time_start (float,
tempo em segundos do comeÃ§o do trecho), time_end (float), transcription (string, contendo o
texto falado no trecho). Link do S3: https://abc. Link do google drive: https://abc.

2. Arquivos mp4. Diversos arquivos mp4 estÃ£o em uma pasta, cada um correspondente um
trecho de 10s. Link do S3: https://abc. Link do google drive: https://abc.

SugestÃµes do que pode ser analisado:
* Realizar a transcripÃ§Ã£o novamente (melhorada de alguma forma)
* Analisar objetos presentes no episÃ³dio
* Agrupar os trechos por tÃ³picos
* Visualizar uma nÃºvem de palavras


#### Boa sorte!
